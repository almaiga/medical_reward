import pandas as pd
import argparse
import os
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def analyze_and_track(result_filepath, tracking_filepath="results/performance_tracking.csv"):
    """
    Analyzes a single result file and appends performance metrics to a tracking CSV.
    """
    print(f"Analyzing file: {result_filepath}")
    
    # 1. Load the results dataframe
    try:
        df = pd.read_csv(result_filepath)
    except FileNotFoundError:
        print(f"Error: File not found at {result_filepath}")
        return

    # 2. Extract metadata from the filename
    filename = os.path.basename(result_filepath)
    parts = filename.replace('_samples.csv', '').split('_', 2)
    timestamp = parts[0] + "_" + parts[1]
    model_name = parts[2]
    num_samples = len(df)

    # 3. Prepare labels for scikit-learn ('INCORRECT' is the positive class)
    y_true = (df['ground_truth_label'] == 'INCORRECT').astype(int)
    y_pred = (df['model_label'] == 'INCORRECT').astype(int)

    # 4. Calculate metrics
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, zero_division=0)
    recall = recall_score(y_true, y_pred, zero_division=0)
    f1 = f1_score(y_true, y_pred, zero_division=0)

    print(f"Metrics for {model_name}:")
    print(f"  Accuracy:  {accuracy:.4f}")
    print(f"  Precision: {precision:.4f}")
    print(f"  Recall:    {recall:.4f}")
    print(f"  F1-Score:  {f1:.4f}")

    # 5. Prepare the new row for the tracking file
    summary_data = {
        'timestamp': [timestamp],
        'model_name': [model_name],
        'num_samples': [num_samples],
        'accuracy': [f"{accuracy:.4f}"],
        'precision': [f"{precision:.4f}"],
        'recall': [f"{recall:.4f}"],
        'f1_score': [f"{f1:.4f}"]
    }
    summary_df = pd.DataFrame(summary_data)

    # 6. Append to the tracking file
    os.makedirs(os.path.dirname(tracking_filepath), exist_ok=True)
    if not os.path.exists(tracking_filepath):
        summary_df.to_csv(tracking_filepath, index=False)
        print(f"Created tracking file at {tracking_filepath}")
    else:
        summary_df.to_csv(tracking_filepath, mode='a', header=False, index=False)
        print(f"Appended results to {tracking_filepath}")

def main():
    parser = argparse.ArgumentParser(description="Analyze model performance from a result file and track it.")
    parser.add_argument(
        "input_file",
        type=str,
        help="Path to the CSV result file generated by run_baseline.py."
    )
    args = parser.parse_args()
    analyze_and_track(args.input_file)

if __name__ == "__main__":
    main()